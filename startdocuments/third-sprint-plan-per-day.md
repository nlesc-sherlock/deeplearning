##Third sprint (16-18 Feb 2016)

## Day 1, Tue 16 Feb
**Learn about SURF Sara HPC cloud; set up DIGITS on own DAS accounts**
* Set up Caffe and DIGITS on our onw accounts (all - Patrick). Please, refer to the [caffe-nv docker](
https://github.com/nlesc-sherlock/deeplearning/blob/master/startdocuments/caffe_nv_docker.md) which he had added to the repo.
* Set up a VM on the SURF Sara HPC cloud on a node with GPU (Patrick)
* Run DIGITS on the platforms (all)
* Lessons learnt text (Elena)

## Day 2, Wed 17 Feb
**Car classification and age/gender use cases- data, training and testing**
* Inventory of how much we use the provided datasets (both subteams for their usecase)
* If needed, get additional data from Internet using scraping scripts (both subteams for their usecase)
* Prepare the data to be used by DIGITS (both subteams for their usecase)
* Learn if and how to import CNN pretrained Caffe models to DIGITS (contrary to our conclusion from sprint 2, 
it might be possible, see this [NVIDIA issue] (https://github.com/NVIDIA/DIGITS/issues/49)) (subteam 1)
* Train/fine-tune the networks (subteam 2)
* Lessons learnt update (both subteams for their usecase)

## Day 3, Thur 18 Feb
**Car classification and age/gender use cases- docker and demo**
* Use the docker container from sprint 2 (classify images given an arbitrary DIGITS trained model) or make new/improved 
version and run it for the 2 use cases. On both DAS and HPC cloud platforms. 
* Prepare small presentation and demo for NLeSc and NFI (Elena- presentaiton, demo- all)
* Lessons learnt update (both subteams for their usecase)
* Demo time (Elena + possibly others)
